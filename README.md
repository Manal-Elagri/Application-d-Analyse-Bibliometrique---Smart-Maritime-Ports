# ğŸš¢ Application d'Analyse BibliomÃ©trique - Smart Maritime Ports

Application Python complÃ¨te et modulaire pour l'analyse bibliomÃ©trique de fichiers Scopus volumineux (20 000 Ã  100 000 lignes) centrÃ©e sur les Smart Maritime Ports.

## ğŸ“‹ Table des matiÃ¨res

- [FonctionnalitÃ©s](#fonctionnalitÃ©s)
- [Installation](#installation)
- [Utilisation](#utilisation)
- [Architecture](#architecture)
- [Modules](#modules)
- [DÃ©pendances](#dÃ©pendances)
- [Configuration Ollama](#configuration-ollama)

## âœ¨ FonctionnalitÃ©s

### 1. Importation optimisÃ©e CSV
- Lecture de fichiers CSV volumineux avec chargement progressif par chunks
- Gestion robuste des erreurs et encodages multiples
- DÃ©tection et suppression automatique des doublons
- Nettoyage avancÃ© des donnÃ©es textuelles

### 2. Analyses bibliomÃ©triques
- **Ã‰volution annuelle** des publications
- **Top auteurs** avec statistiques dÃ©taillÃ©es
- **Top journaux** et sources
- **Top mots-clÃ©s** avec frÃ©quences
- **Matrice de co-occurrence** des mots-clÃ©s
- **RÃ©seau de co-auteurs** avec filtrage intelligent
- **Clustering thÃ©matique** via TF-IDF + KMeans
- **LDA Topic Modeling** pour l'identification de topics

### 3. Visualisations
- Graphiques matplotlib optimisÃ©s (PNG, SVG, PDF)
- RÃ©seaux interactifs avec PyVis
- Nuages de mots (WordCloud) thÃ©matiques
- Graphiques de distribution et Ã©volution temporelle

### 4. IntÃ©gration IA (Ollama)
- RÃ©sumÃ© de clusters d'abstracts
- Analyse des tendances scientifiques
- InterprÃ©tation de graphes de co-occurrence
- GÃ©nÃ©ration de recommandations de recherche
- Analyse complÃ¨te automatisÃ©e

### 5. Export PDF
- GÃ©nÃ©ration de rapports PDF professionnels
- IntÃ©gration d'images et analyses IA
- Mise en page propre et structurÃ©e
- Export de toutes les visualisations

## ğŸš€ Installation

### PrÃ©requis
- Python 3.8 ou supÃ©rieur
- Ollama (pour les fonctionnalitÃ©s IA) - optionnel mais recommandÃ©

### Ã‰tapes d'installation

1. **Cloner ou tÃ©lÃ©charger le projet**

2. **CrÃ©er un environnement virtuel** (recommandÃ©)
```bash
python -m venv env
```

3. **Activer l'environnement virtuel**
   - Windows:
     ```bash
     env\Scripts\activate
     ```
   - Linux/Mac:
     ```bash
     source env/bin/activate
     ```

4. **Installer les dÃ©pendances**
```bash
pip install -r requirements.txt
```

5. **TÃ©lÃ©charger les ressources NLTK** (automatique au premier lancement)
   - Les ressources nÃ©cessaires seront tÃ©lÃ©chargÃ©es automatiquement
   - Si nÃ©cessaire, vous pouvez les tÃ©lÃ©charger manuellement:
   ```python
   import nltk
   nltk.download('punkt')
   nltk.download('stopwords')
   ```

6. **Installer et configurer Ollama** (pour les fonctionnalitÃ©s IA)
   - TÃ©lÃ©charger Ollama depuis [https://ollama.ai](https://ollama.ai)
   - Installer le modÃ¨le requis:
   ```bash
   ollama run deepseek-r1:1.5b
   ```
   - VÃ©rifier que Ollama est dÃ©marrÃ©:
   ```bash
   ollama serve
   ```

## ğŸ“– Utilisation

### Lancement de l'interface Streamlit

```bash
streamlit run app/interface.py
```

L'application sera accessible dans votre navigateur Ã  l'adresse `http://localhost:8501`

### Workflow recommandÃ©

1. **Importation des donnÃ©es**
   - AccÃ©dez Ã  l'onglet "ğŸ“Š Importation des donnÃ©es"
   - TÃ©lÃ©versez votre fichier CSV Scopus
   - Configurez les options de nettoyage (suppression des doublons)
   - Cliquez sur "ğŸ”§ PrÃ©parer les donnÃ©es"

2. **Analyses bibliomÃ©triques**
   - AccÃ©dez Ã  l'onglet "ğŸ“ˆ Analyses bibliomÃ©triques"
   - Explorez les diffÃ©rents onglets:
     - Ã‰volution annuelle
     - Top auteurs
     - Top journaux
     - Top mots-clÃ©s
     - Statistiques gÃ©nÃ©rales
   - TÃ©lÃ©chargez les rÃ©sultats en CSV si nÃ©cessaire

3. **RÃ©seaux et visualisations**
   - AccÃ©dez Ã  l'onglet "ğŸ•¸ï¸ RÃ©seaux et visualisations"
   - GÃ©nÃ©rez le rÃ©seau de co-occurrence des mots-clÃ©s
   - Explorez le rÃ©seau interactif
   - CrÃ©ez un nuage de mots
   - Effectuez un clustering thÃ©matique
   - TÃ©lÃ©chargez les visualisations

4. **Analyse IA**
   - AccÃ©dez Ã  l'onglet "ğŸ¤– Analyse IA"
   - Analysez un graphe gÃ©nÃ©rÃ©
   - Analysez les tendances scientifiques
   - Analysez un cluster spÃ©cifique
   - Obtenez des recommandations de recherche

5. **Export PDF**
   - AccÃ©dez Ã  l'onglet "ğŸ“„ Export PDF"
   - Configurez les options d'inclusion
   - GÃ©nÃ©rez le rapport PDF complet
   - TÃ©lÃ©chargez le PDF

### Utilisation en ligne de commande

Vous pouvez Ã©galement utiliser les modules directement dans votre code Python:

```python
from app.load_data import load_scopus_csv, remove_duplicates
from app.preprocess import preprocess_dataframe
from app.bibliometry import annual_evolution, top_authors, top_keywords
from app.networks import create_cooccurrence_network
from app.visualizations import plot_annual_evolution, plot_network_graph

# Charger les donnÃ©es
df = load_scopus_csv("data/scopus_data.csv", chunksize=5000)
df = remove_duplicates(df)
df_processed = preprocess_dataframe(df)

# Analyses
annual_df = annual_evolution(df_processed)
top_auth = top_authors(df_processed, top_n=20)
top_kw = top_keywords(df_processed, top_n=50)

# Visualisations
plot_annual_evolution(annual_df, "exports/evolution")
```

## ğŸ—ï¸ Architecture

```
Simulation_Smart_Port/
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py                 # Point d'entrÃ©e
â”‚   â”œâ”€â”€ interface.py            # Interface Streamlit
â”‚   â”œâ”€â”€ load_data.py            # Importation CSV optimisÃ©e
â”‚   â”œâ”€â”€ preprocess.py           # PrÃ©processing et nettoyage
â”‚   â”œâ”€â”€ bibliometry.py          # Analyses bibliomÃ©triques
â”‚   â”œâ”€â”€ networks.py              # CrÃ©ation de rÃ©seaux
â”‚   â”œâ”€â”€ nlp_models.py            # Clustering et LDA
â”‚   â”œâ”€â”€ visualizations.py       # GÃ©nÃ©ration de graphiques
â”‚   â”œâ”€â”€ ai_analysis.py          # IntÃ©gration Ollama
â”‚   â”œâ”€â”€ pdf_generator.py        # GÃ©nÃ©ration PDF
â”‚   â””â”€â”€ utils.py                # Fonctions utilitaires
â”‚
â”œâ”€â”€ data/                       # Dossier pour les fichiers CSV
â”œâ”€â”€ exports/                    # Dossier pour les exports (PDF, images, CSV)
â”‚
â”œâ”€â”€ requirements.txt            # DÃ©pendances Python
â””â”€â”€ README.md                   # Ce fichier
```

## ğŸ“¦ Modules

### `load_data.py`
- `load_scopus_csv()`: Chargement optimisÃ© de fichiers CSV volumineux
- `detect_duplicates()`: DÃ©tection de doublons
- `remove_duplicates()`: Suppression de doublons

### `preprocess.py`
- `normalize_text()`: Normalisation de texte
- `remove_stopwords()`: Suppression des stopwords
- `clean_abstract()`: Nettoyage des abstracts
- `clean_keywords()`: Nettoyage des mots-clÃ©s
- `preprocess_dataframe()`: PrÃ©processing complet d'un DataFrame

### `bibliometry.py`
- `annual_evolution()`: Ã‰volution annuelle des publications
- `top_authors()`: Top auteurs
- `top_journals()`: Top journaux
- `top_keywords()`: Top mots-clÃ©s
- `co_occurrence_matrix()`: Matrice de co-occurrence
- `get_statistics()`: Statistiques gÃ©nÃ©rales

### `networks.py`
- `create_cooccurrence_network()`: RÃ©seau de co-occurrence
- `create_coauthors_network()`: RÃ©seau de co-auteurs
- `get_network_metrics()`: MÃ©triques de rÃ©seau
- `filter_network_by_degree()`: Filtrage par degrÃ©

### `nlp_models.py`
- `tfidf_clustering()`: Clustering TF-IDF + KMeans
- `get_cluster_keywords()`: Extraction de mots-clÃ©s par cluster
- `lda_topic_modeling()`: ModÃ©lisation LDA
- `get_lda_topics()`: Extraction des topics LDA

### `visualizations.py`
- `plot_annual_evolution()`: Graphique d'Ã©volution annuelle
- `plot_top_items()`: Graphique en barres
- `plot_network_graph()`: Visualisation de rÃ©seau
- `create_wordcloud()`: Nuage de mots
- `create_interactive_network()`: RÃ©seau interactif PyVis
- `plot_cluster_distribution()`: Distribution des clusters

### `ai_analysis.py`
- `ask_ai()`: Fonction principale de communication avec Ollama
- `analyze_cluster()`: Analyse d'un cluster
- `analyze_trends()`: Analyse des tendances
- `analyze_graph()`: Analyse d'un graphe
- `generate_research_recommendations()`: Recommandations de recherche
- `generate_comprehensive_analysis()`: Analyse complÃ¨te

### `pdf_generator.py`
- `generate_pdf()`: GÃ©nÃ©ration d'un PDF simple
- `generate_comprehensive_report()`: GÃ©nÃ©ration d'un rapport complet

### `utils.py`
- Fonctions utilitaires diverses (gestion de fichiers, normalisation, etc.)

## ğŸ”§ DÃ©pendances

Les principales dÃ©pendances sont listÃ©es dans `requirements.txt`:

- **pandas, numpy**: Traitement de donnÃ©es
- **streamlit**: Interface utilisateur
- **matplotlib, seaborn, plotly**: Visualisations
- **networkx, pyvis**: RÃ©seaux et graphes
- **nltk, scikit-learn, gensim**: NLP et machine learning
- **wordcloud**: Nuages de mots
- **reportlab, fpdf**: GÃ©nÃ©ration PDF
- **requests**: Communication avec Ollama

## ğŸ¤– Configuration Ollama

### Installation d'Ollama

1. TÃ©lÃ©charger depuis [https://ollama.ai](https://ollama.ai)
2. Installer selon votre systÃ¨me d'exploitation
3. DÃ©marrer le serveur Ollama:
   ```bash
   ollama serve
   ```

### Installation du modÃ¨le

```bash
ollama run deepseek-r1:1.5b
```

### VÃ©rification

Pour vÃ©rifier que tout fonctionne:

```python
from app.ai_analysis import ask_ai
response = ask_ai("Bonjour, peux-tu te prÃ©senter?")
print(response)
```

### Configuration personnalisÃ©e

Si vous utilisez un autre modÃ¨le ou endpoint, modifiez les constantes dans `app/ai_analysis.py`:

```python
OLLAMA_ENDPOINT = "http://localhost:11434/api/generate"
OLLAMA_MODEL = "votre-modele"
```

## ğŸ“Š Format des donnÃ©es d'entrÃ©e

Le fichier CSV Scopus doit contenir au minimum les colonnes suivantes:

- `Title`: Titre de la publication
- `Abstract`: RÃ©sumÃ©
- `Author Keywords`: Mots-clÃ©s (sÃ©parÃ©s par `;` ou `,`)
- `Authors`: Liste des auteurs (sÃ©parÃ©s par `;`)
- `Year`: AnnÃ©e de publication
- `Source title`: Titre de la source/journal

## ğŸ› DÃ©pannage

### Erreur de chargement CSV
- VÃ©rifiez l'encodage du fichier (UTF-8 recommandÃ©)
- VÃ©rifiez que les colonnes requises sont prÃ©sentes
- RÃ©duisez la taille des chunks si nÃ©cessaire

### Erreur Ollama
- VÃ©rifiez que Ollama est dÃ©marrÃ©: `ollama serve`
- VÃ©rifiez que le modÃ¨le est installÃ©: `ollama list`
- VÃ©rifiez la connexion: `curl http://localhost:11434/api/generate`

### Erreur de mÃ©moire
- RÃ©duisez la taille des chunks lors du chargement
- Filtrez les donnÃ©es avant le traitement
- Utilisez le filtrage des rÃ©seaux pour rÃ©duire le nombre de nÅ“uds

## ğŸ“ Notes

- Les fichiers gÃ©nÃ©rÃ©s sont sauvegardÃ©s dans le dossier `exports/`
- Les visualisations sont gÃ©nÃ©rÃ©es en haute rÃ©solution (300 DPI)
- Les analyses IA peuvent prendre quelques secondes selon la complexitÃ©
- Pour de trÃ¨s gros fichiers (>100k lignes), le traitement peut Ãªtre long

## ğŸ“„ Licence

Ce projet est fourni tel quel pour usage acadÃ©mique et de recherche.

## ğŸ‘¥ Contribution

Les contributions sont les bienvenues! N'hÃ©sitez pas Ã  ouvrir une issue ou une pull request.

## ğŸ“§ Support

Pour toute question ou problÃ¨me, veuillez ouvrir une issue sur le dÃ©pÃ´t du projet.

---

**Bonnes analyses bibliomÃ©triques! ğŸš¢ğŸ“Š**

